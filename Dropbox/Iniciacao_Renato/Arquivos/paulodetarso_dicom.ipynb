{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analisando os dados nas redes sociais, com menções da marca FGV e derivadas da mesma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Criando um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transformamos os arquivos .csv em arquivos .xls para facilitar a transformação em um dataframe\n",
    "df_dicom = pd.read_excel(\"/home/paulo/Dropbox/Iniciacao_Renato/Arquivos/8_PlanetaY_Ago2014.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pequenas modificações\n",
    "df_dicom[\"CLASS\"] = df_dicom.values[:,1]\n",
    "df_dicom[\"User\"] = df_dicom.values[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TESTE']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#função para retirar acentuação e símbolos\n",
    "def clean_string(s):\n",
    "    s = unicodedata.normalize('NFKD', unicode(s)).encode('ascii','ignore')\n",
    "    delete_symbols = string.punctuation\n",
    "    delete_words = nltk.corpus.stopwords.words('portuguese')\n",
    "    string_1 = ''\n",
    "    string_2 = []\n",
    "    #limpando os símbolos\n",
    "    for letter in s:\n",
    "        if letter not in delete_symbols:\n",
    "            string_1 += letter\n",
    "        else:\n",
    "            string_1 += ' '\n",
    "    string_1 = string_1.split()\n",
    "    #limpando as stopwords\n",
    "    for word in string_1:\n",
    "        if word not in delete_words:\n",
    "            string_2.append(word)\n",
    "    return [word.upper() for word in string_2]\n",
    "\n",
    "clean_string(\"Teste*!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treinando o classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def treinar(df,train_percent): #train_percent -> porcentagem de frases que serão usadas pra treinar o classificador\n",
    "    pos_texts = df[df[\"CLASS\"]==\"Positiva\"][\"Texto\"].tolist()\n",
    "    neg_texts = df[df[\"CLASS\"]==\"Negativa\"][\"Texto\"].tolist()\n",
    "    neut_texts = df[df[\"CLASS\"]==\"Neutra\"][\"Texto\"].tolist()\n",
    "    tam = min(len(pos_texts),len(neg_texts),len(neut_texts))\n",
    "    \n",
    "    #limpando os textos\n",
    "    pos_clean = [clean_string(p) for p in pos_texts[:tam]]\n",
    "    neg_clean = [clean_string(p) for p in neg_texts[:tam]]\n",
    "    neut_clean = [clean_string(p) for p in neut_texts[:tam]]\n",
    "    \n",
    "    #frases para treino\n",
    "    a = int(round(train_percent*tam))\n",
    "    pos_train = pos_clean[:a]\n",
    "    neg_train = neg_clean[:a]\n",
    "    neut_train = neut_clean[:a]\n",
    "    \n",
    "    #frases para teste\n",
    "    pos_test = pos_clean[a:tam]\n",
    "    neg_test = neg_clean[a:tam]\n",
    "    neut_test = neut_clean[a:tam]\n",
    "    \n",
    "    #dicionários com as contagens das palavras\n",
    "    words_count_pos = dict()\n",
    "    words_count_neg = dict()\n",
    "    words_count_neut = dict()\n",
    "    \n",
    "    #adiciono 1 a cada contagem, para que não haja nenhuma palavra com contagem 0, e sejam evitados certos erros\n",
    "    for p in neg_clean+neut_clean+pos_clean:\n",
    "        for word in p:\n",
    "            words_count_pos[word] = 1\n",
    "            words_count_neg[word] = 1\n",
    "            words_count_neut[word] = 1\n",
    "    \n",
    "    #adiciono 1 para cada palavra em cada lista, dada sua classificação\n",
    "    for i in range(a):\n",
    "        p = pos_train[i]\n",
    "        for word in p:\n",
    "            words_count_pos[word] += 1\n",
    "        p = neg_train[i]\n",
    "        for word in p:\n",
    "            words_count_neg[word] += 1\n",
    "        p = neut_train[i]\n",
    "        for word in p:\n",
    "            words_count_neut[word] += 1\n",
    "    return words_count_pos,words_count_neg,words_count_neut,tam,pos_test,neg_test,neut_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Avaliando as probabilidades de cada palavra e frase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#probabilidade de uma palavra apenas\n",
    "def prob(palavra,words_count_pos,words_count_neg,words_count_neut):\n",
    "    a = float(words_count_pos[palavra])\n",
    "    b = float(words_count_neg[palavra])\n",
    "    c = float(words_count_neut[palavra])\n",
    "    #retorna uma tripla, do tipo [prob_positiva, prob_negativa, prob_neutra]\n",
    "    return [(a/(a+b+c)),(b/(a+b+c)),(c/(a+b+c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#avalia cada frase, por meio do produto das probabilidades de cada palavra\n",
    "def eval_phrase(phrase,words_count_pos,words_count_neg,words_count_neut):\n",
    "    pr = [1/3.,1/3.,1/3.]\n",
    "    c = ''\n",
    "    for word in phrase:\n",
    "        aux = prob(word,words_count_pos,words_count_neg,words_count_neut)\n",
    "        pr[0] *= aux[0]\n",
    "        pr[1] *= aux[1]\n",
    "        pr[2] *= aux[2]\n",
    "    n = pr.index(max(pr))\n",
    "    #sabendo a posição do maior produto de probabilidades\n",
    "    #podemos dizer qual a sua avaliação\n",
    "    if n == 0: c = \"Positiva\"\n",
    "    elif n == 1: c = \"Negativa\"\n",
    "    else: c = \"Neutra\"\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Criando o classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classificador1(df,train_percent = 0.9):\n",
    "    aux = treinar(df,train_percent)\n",
    "    \n",
    "    #contagem das palavras\n",
    "    words_count_pos = aux[0]\n",
    "    words_count_neg = aux[1]\n",
    "    words_count_neut = aux[2]\n",
    "    \n",
    "    #textos para teste\n",
    "    pos_test = aux[4]\n",
    "    neg_test = aux[5]\n",
    "    neut_test = aux[6]\n",
    "    \n",
    "    #todas as frases positivas para teste\n",
    "    all_for_test = pos_test + neg_test + neut_test\n",
    "    \n",
    "    #tamanho de cada lista de frases para classificação\n",
    "    tam1 = len(pos_test) \n",
    "    tam2 = len(neg_test)\n",
    "    tam3= len(neut_test)\n",
    "    \n",
    "    #ponho lado a lado as classificações das frases (função eval_phrase) e\n",
    "    #uma lista com as classificações esperadas. Então, comparo termo a termo.\n",
    "    #Isso reduz a complexidade para linear.\n",
    "    classifications = [\"Positiva\" for i in range(tam1)] + [\"Negativa\" for i in range(tam2)] + [\"Neutra\" for i in range(tam3)]\n",
    "    class_list = [eval_phrase(p,words_count_pos,words_count_neg,words_count_neut) for p in all_for_test]\n",
    "    \n",
    "    #crio um contador, que, a cada acerto, incrementa em uma unidade.\n",
    "    counter = 0.\n",
    "    for i in range(tam1+tam2+tam3):\n",
    "        if class_list[i] == classifications[i]:\n",
    "            counter += 1\n",
    "    #ao final, divido a contagem de acertos pela soma dos tamanhos das listas de frases destinadas à classificação\n",
    "    print \"A porcentagem de acertos do classificador é \", (counter/(tam1+tam2+tam3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de acertos do classificador é  0.8\n"
     ]
    }
   ],
   "source": [
    "classificador1(df_dicom,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
